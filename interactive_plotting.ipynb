{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 301 nearest neighbors...\n",
      "[t-SNE] Indexed 1715 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 1715 samples in 0.180s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 1715\n",
      "[t-SNE] Computed conditional probabilities for sample 1715 / 1715\n",
      "[t-SNE] Mean sigma: 0.093470\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 60.540424\n",
      "[t-SNE] KL divergence after 1000 iterations: 0.922935\n"
     ]
    }
   ],
   "source": [
    "# interactive plot to check DVN results\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.manifold import TSNE, Isomap, LocallyLinearEmbedding, SpectralEmbedding\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from ast import literal_eval\n",
    "import io\n",
    "from PIL import Image\n",
    "import librosa\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import torch\n",
    "from feature_extraction import pytorch_utils as pu\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "import os, random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "n_neighbors = 10\n",
    "FREQ_BINS=30\n",
    "TIME_STEPS=20\n",
    "SR=44100\n",
    "\n",
    "def plotly_able_df(df,num_d=2):\n",
    "    \n",
    "    df[\"feats\"]=df[\"feats\"].apply(literal_eval)\n",
    "    X=df[\"feats\"]\n",
    "    #convert series of arrays into a numpy array\n",
    "    X=pd.DataFrame(X.to_list()).to_numpy()\n",
    "    X = min_max_scaler.fit_transform(X)\n",
    "    time_start = time.time()\n",
    "    tsne = TSNE(n_components=num_d, random_state=0, perplexity=100, verbose=1)\n",
    "#     tsne = Isomap(n_neighbors, n_components=num_d)\n",
    "#     tsne = LocallyLinearEmbedding(n_neighbors,n_components=num_d)\n",
    "#     tsne = SpectralEmbedding(n_neighbors=10,n_components=num_d,random_state=1)\n",
    "    X_2d = tsne.fit_transform(X)\n",
    "    \n",
    "    if num_d==2:\n",
    "        df2=pd.concat([df[\"path\"],df[\"label\"],df[\"drum_type\"],pd.Series(X_2d[:,0]),pd.Series(X_2d[:,1])],axis=1)\n",
    "        df2.columns=[\"path\",\"label\",\"drum_type\",\"D1\",\"D2\"]\n",
    "    if num_d==3:\n",
    "        df2=pd.concat([df[\"path\"],df[\"label\"],df[\"drum_type\"],pd.Series(X_2d[:,0]),pd.Series(X_2d[:,1]),pd.Series(X_2d[:,2])],axis=1)\n",
    "        df2.columns=[\"path\",\"label\",\"drum_type\",\"D1\",\"D2\",\"D3\"]\n",
    "    \n",
    "    df2.label = df2.label.astype('str')\n",
    "    return df2\n",
    "\n",
    "class interactive_graph():\n",
    "    def hover_fn(self,trace, points, state):\n",
    "        if points.point_inds:\n",
    "            ind = points.point_inds[0]\n",
    "            drmName=trace.customdata[ind][0][2:]\n",
    "            filename=os.getcwd()+\"/\"+drmName\n",
    "            with open(filename,'rb') as f:\n",
    "                audio_data = f.read()\n",
    "            self.aud.value=audio_data\n",
    "            self.hover_data.value = str(drmName)+\"\\n\"\n",
    "            self.audioImg.value=self.audDisplay(filename)\n",
    "            \n",
    "    def audDisplay(self,f):\n",
    "        #this got annoying because widget only accepts byte version of images\n",
    "        audio_array=librosa.load(f)\n",
    "        signals=audio_array[0]\n",
    "        nz=np.max((SR-signals.shape[0],0))\n",
    "        signals=np.concatenate([signals[0:SR],np.zeros(nz)]).astype(\"float32\")\n",
    "\n",
    "        sound={\"signal\":torch.tensor(signals),\"label\":'',\"path\":'',\"drum_type\":''}\n",
    "        trns=pu.specTrans(FREQ_BINS,time_steps=TIME_STEPS)\n",
    "        ft=trns(sound)[\"feats\"]\n",
    "        sf=ft.detach().numpy()[0]\n",
    "        #flip upside down\n",
    "        sf=sf[-1:0:-1][:]\n",
    "        x=plt.imshow(sf)\n",
    "        #convert to bytes so can be set to widget data\n",
    "        buf = io.BytesIO()\n",
    "        x.figure.savefig(buf, format='png')\n",
    "        buf.seek(0)\n",
    "        bufD=buf.getvalue()\n",
    "        buf.close()\n",
    "        \n",
    "        return bufD\n",
    "    def __init__(self,df,grouping_by=\"label\",title=\"\",num_d=2,sym_size=10):\n",
    "        if num_d==2:\n",
    "            p = px.scatter(df, x=\"D1\",y=\"D2\",color=grouping_by,hover_data=[\"path\"],color_discrete_sequence=px.colors.qualitative.Dark24)\n",
    "        elif num_d==3:\n",
    "            p = px.scatter_3d(df, x=\"D1\",y=\"D2\",z=\"D3\",color=grouping_by,hover_data=[\"path\"],symbol=\"label\",color_discrete_sequence=px.colors.qualitative.Dark24)\n",
    "        for trace in p.data:\n",
    "            trace.update(hoverinfo=\"none\",hovertemplate= '')\n",
    "        p.update_traces(marker=dict(size=sym_size,\n",
    "                              line=dict(width=1,\n",
    "                                        color='DarkSlateGrey')),\n",
    "                  selector=dict(mode='markers'))\n",
    "\n",
    "        self.hover_data = widgets.Textarea()  \n",
    "        #audio and img widgets\n",
    "        self.aud=widgets.Audio(autoplay=True,loop=False,embedding=True)\n",
    "        self.audioImg=widgets.Image(\n",
    "            value=b'',\n",
    "            format='png',\n",
    "            width='30%', \n",
    "        )\n",
    "        #####\n",
    "        layout = go.Layout(hovermode=False,)\n",
    "        self.fig  = go.FigureWidget(p)\n",
    "        self.fig.update_layout(scene = dict(\n",
    "                    camera=dict(eye=dict(x=-1, y=-1, z=0)),\n",
    "                    aspectmode=\"cube\",),\n",
    "                    margin=dict( r=0, l=0, b=0, t=0))\n",
    "                    \n",
    "        for f in self.fig.data:\n",
    "            f.on_hover(self.hover_fn)        \n",
    "\n",
    "\n",
    "# df_64_3d=plotly_able_df(pd.read_csv(\"feature_extraction/csvs/spec_encode_64_290_0.002042.pt.csv\"),num_d=3)\n",
    "# df_8_3d=plotly_able_df(pd.read_csv(\"feature_extraction/csvs/spec_encode_sm_8_270_0.003504.pt.csv\"),num_d=3,)\n",
    "# df_64_2d=plotly_able_df(pd.read_csv(\"feature_extraction/csvs/spec_encode_64_290_0.002042.pt.csv\"),num_d=2)\n",
    "df_8_2d=plotly_able_df(pd.read_csv(\"feature_extraction/csvs/spec_encode_sm_8_270_0.003504.pt.csv\"),num_d=2,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>drum_type</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>./dk_data/tom_high/Roland Tr-909-TR-909Tom Hi ...</td>\n",
       "      <td>0</td>\n",
       "      <td>tom_high</td>\n",
       "      <td>-9.182418</td>\n",
       "      <td>14.273406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>./dk_data/tom_high/Kawai R50e-R50eTomA_Hi.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>tom_high</td>\n",
       "      <td>-9.236695</td>\n",
       "      <td>15.736501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>./dk_data/tom_high/Vermona Drum-MaxV - Tom Hi.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>tom_high</td>\n",
       "      <td>-12.695660</td>\n",
       "      <td>1.759251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>./dk_data/tom_high/Kawai R50-R50 TomH.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>tom_high</td>\n",
       "      <td>-2.663086</td>\n",
       "      <td>19.301695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>./dk_data/tom_high/Alesis Hr16-MaxV - HR16 10-...</td>\n",
       "      <td>0</td>\n",
       "      <td>tom_high</td>\n",
       "      <td>-10.416052</td>\n",
       "      <td>14.428359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1710</td>\n",
       "      <td>./dk_data/synth_noise/UUB9-1770-1.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>synth_noise</td>\n",
       "      <td>15.410675</td>\n",
       "      <td>-12.485955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1711</td>\n",
       "      <td>./dk_data/synth_noise/ZJXB-238-1.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>synth_noise</td>\n",
       "      <td>1.048341</td>\n",
       "      <td>0.393385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1712</td>\n",
       "      <td>./dk_data/synth_noise/838-8-XBHZ.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>synth_noise</td>\n",
       "      <td>10.064046</td>\n",
       "      <td>-3.682528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1713</td>\n",
       "      <td>./dk_data/synth_noise/NH29-1189-4.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>synth_noise</td>\n",
       "      <td>-1.173597</td>\n",
       "      <td>-3.846659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1714</td>\n",
       "      <td>./dk_data/synth_noise/D3X4-1644-4.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>synth_noise</td>\n",
       "      <td>-4.785655</td>\n",
       "      <td>-1.648925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1715 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path label    drum_type  \\\n",
       "0     ./dk_data/tom_high/Roland Tr-909-TR-909Tom Hi ...     0     tom_high   \n",
       "1         ./dk_data/tom_high/Kawai R50e-R50eTomA_Hi.wav     0     tom_high   \n",
       "2     ./dk_data/tom_high/Vermona Drum-MaxV - Tom Hi.wav     0     tom_high   \n",
       "3             ./dk_data/tom_high/Kawai R50-R50 TomH.wav     0     tom_high   \n",
       "4     ./dk_data/tom_high/Alesis Hr16-MaxV - HR16 10-...     0     tom_high   \n",
       "...                                                 ...   ...          ...   \n",
       "1710              ./dk_data/synth_noise/UUB9-1770-1.wav     1  synth_noise   \n",
       "1711               ./dk_data/synth_noise/ZJXB-238-1.wav     1  synth_noise   \n",
       "1712               ./dk_data/synth_noise/838-8-XBHZ.wav     1  synth_noise   \n",
       "1713              ./dk_data/synth_noise/NH29-1189-4.wav     1  synth_noise   \n",
       "1714              ./dk_data/synth_noise/D3X4-1644-4.wav     1  synth_noise   \n",
       "\n",
       "             D1         D2  \n",
       "0     -9.182418  14.273406  \n",
       "1     -9.236695  15.736501  \n",
       "2    -12.695660   1.759251  \n",
       "3     -2.663086  19.301695  \n",
       "4    -10.416052  14.428359  \n",
       "...         ...        ...  \n",
       "1710  15.410675 -12.485955  \n",
       "1711   1.048341   0.393385  \n",
       "1712  10.064046  -3.682528  \n",
       "1713  -1.173597  -3.846659  \n",
       "1714  -4.785655  -1.648925  \n",
       "\n",
       "[1715 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_8_3d.to_csv(\"./feature_extraction/csvs/df_8_3D.csv\",index=False)\n",
    "df_64_3d.to_csv(\"./feature_extraction/csvs/df_64_3D.csv\",index=False)\n",
    "df_8_2d.to_csv(\"./feature_extraction/csvs/df_8_2D.csv\",index=False)\n",
    "df_64_2d.to_csv(\"./feature_extraction/csvs/df_64_2D.csv\",index=False)\n",
    "df_8_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig=interactive_graph(df_8,grouping_by=\"drum_type\",title=\"8 dim embedding\",num_d=3,sym_size=3)\n",
    "\n",
    "display(ig.fig,widgets.HBox([ig.hover_data,ig.aud,ig.audioImg]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
