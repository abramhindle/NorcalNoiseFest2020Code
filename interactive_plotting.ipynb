{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive plot to check DVN results\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.manifold import TSNE, Isomap, LocallyLinearEmbedding, SpectralEmbedding\n",
    "import plotly_express as px\n",
    "import plotly.graph_objs as go\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from ast import literal_eval\n",
    "import io\n",
    "from PIL import Image\n",
    "import librosa\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import torch\n",
    "from feature_extraction import pytorch_utils as pu\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "import os, random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "n_neighbors = 10\n",
    "FREQ_BINS=30\n",
    "TIME_STEPS=20\n",
    "SR=44100\n",
    "class interactive_graph():\n",
    "    def __init__(self,df,grouping_by=\"label\",title=\"\"):\n",
    "        p = px.scatter(df, x=\"v1\",y=\"v2\",color=grouping_by,hover_data=[\"path\"],color_discrete_sequence=px.colors.qualitative.Dark24)\n",
    "    \n",
    "        for trace in p.data:\n",
    "            trace.update(hoverinfo=\"none\",hovertemplate= '')\n",
    "        \n",
    "        self.hover_data = widgets.Textarea()  \n",
    "        #audio and img widgets\n",
    "        self.aud=widgets.Audio(autoplay=True,loop=False,embedding=True)\n",
    "        self.audioImg=widgets.Image(\n",
    "            value=b'',\n",
    "            format='png',\n",
    "            width='30%', \n",
    "        )\n",
    "        #####\n",
    "        layout = go.Layout(hovermode=False,)\n",
    "        self.fig  = go.FigureWidget(p)\n",
    "        self.fig.update_layout(\n",
    "            title={\n",
    "                'text': title,\n",
    "                'y':0.9,\n",
    "                'x':0.5,\n",
    "                'xanchor': 'center',\n",
    "                'yanchor': 'top'})\n",
    "        for f in self.fig.data:\n",
    "            f.on_hover(self.hover_fn)\n",
    "    \n",
    "    \n",
    "    def hover_fn(self,trace, points, state):\n",
    "        if points.point_inds:\n",
    "            ind = points.point_inds[0]\n",
    "            drmName=trace.customdata[ind][0][2:]\n",
    "            filename=os.getcwd()+\"/\"+drmName\n",
    "            with open(filename,'rb') as f:\n",
    "                audio_data = f.read()\n",
    "            self.aud.value=audio_data\n",
    "            self.hover_data.value = str(drmName)+\"\\n\"\n",
    "            self.audioImg.value=self.audDisplay(filename)\n",
    "            \n",
    "    def audDisplay(self,f):\n",
    "        #this got annoying because widget only accepts byte version of images\n",
    "        audio_array=librosa.load(f)\n",
    "        signals=audio_array[0]\n",
    "        nz=np.max((SR-signals.shape[0],0))\n",
    "        signals=np.concatenate([signals[0:SR],np.zeros(nz)]).astype(\"float32\")\n",
    "\n",
    "        sound={\"signal\":torch.tensor(signals),\"label\":'',\"path\":'',\"drum_type\":''}\n",
    "        trns=pu.specTrans(FREQ_BINS,time_steps=TIME_STEPS)\n",
    "        ft=trns(sound)[\"feats\"]\n",
    "        sf=ft.detach().numpy()[0]\n",
    "        #flip upside down\n",
    "        sf=sf[-1:0:-1][:]\n",
    "        plt.tight_layout()\n",
    "        x=plt.imshow(sf)\n",
    "        #convert to bytes so can be set to widget data\n",
    "        buf = io.BytesIO()\n",
    "        x.figure.savefig(buf, format='png')\n",
    "        buf.seek(0)\n",
    "        bufD=buf.getvalue()\n",
    "        buf.close()    \n",
    "        return bufD\n",
    "def plotly_able_df(df):\n",
    "    \n",
    "    df[\"feats\"]=df[\"feats\"].apply(literal_eval)\n",
    "    X=df[\"feats\"]\n",
    "    #convert series of arrays into a numpy array\n",
    "    X=pd.DataFrame(X.to_list()).to_numpy()\n",
    "    X = min_max_scaler.fit_transform(X)\n",
    "    time_start = time.time()\n",
    "#     tsne = TSNE(n_components=2, random_state=0, perplexity=100, verbose=1)\n",
    "    tsne = Isomap(n_neighbors, n_components=2)\n",
    "    # tsne = LocallyLinearEmbedding(n_neighbors,n_components=4)\n",
    "    # tsne = SpectralEmbedding(n_neighbors=10,n_components=5,random_state=1)\n",
    "    X_2d = tsne.fit_transform(X)\n",
    "    df2=pd.concat([df[\"path\"],df[\"label\"],df[\"drum_type\"],pd.Series(X_2d[:,0]),pd.Series(X_2d[:,1])],axis=1)\n",
    "    df2.columns=[\"path\",\"label\",\"drum_type\",\"v1\",\"v2\"]\n",
    "    df2.label = df2.label.astype('str')\n",
    "    return df2\n",
    "\n",
    "df_64=plotly_able_df(pd.read_csv(\"feature_extraction/csvs/spec_encode_64_290_0.002042.pt.csv\"))\n",
    "df_8=plotly_able_df(pd.read_csv(\"feature_extraction/csvs/spec_encode_sm_8_270_0.003504.pt.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4794ed816f44979b43d47c103a91e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'customdata': array([['./dk_data/tom_high/Roland Tr-909-TR-909Tom Hi 01.wav'],\n",
       "  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7bf57e424ca4681a64d6e8311a38680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Textarea(value=''), Audio(value=b'', loop='False'), Image(value=b'', width='30%')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ig=interactive_graph(df_64,grouping_by=\"drum_type\",title=\"64 dim embedding\")\n",
    "\n",
    "display(ig.fig,widgets.HBox([ig.hover_data,ig.aud,ig.audioImg]))\n",
    "\n",
    "# ig=interactive_graph(df_64,grouping_by=\"label\",title=\"64 dim embedding\")\n",
    "# display(ig.fig,widgets.HBox([ig.hover_data,ig.aud]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa31c86bb0824313a39b13e10174e734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'customdata': array([['./dk_data/tom_high/Roland Tr-909-TR-909Tom Hi 01.wav'],\n",
       "  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ac311685934b179d0bcae220a95244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Textarea(value=''), Audio(value=b'', loop='False')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0aaf2111dfd41acb1be2596d5717093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'customdata': array([['./dk_data/tom_high/Roland Tr-909-TR-909Tom Hi 01.wav'],\n",
       "  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1b2eb302f147a4b948e573cfbe0d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Textarea(value=''), Audio(value=b'', loop='False')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ig=interactive_graph(df_8,grouping_by=\"drum_type\",title=\"8 dim embedding\")\n",
    "display(ig.fig,widgets.HBox([ig.hover_data,ig.aud]))\n",
    "\n",
    "ig=interactive_graph(df_8,grouping_by=\"label\",title=\"8 dim embedding\")\n",
    "display(ig.fig,widgets.HBox([ig.hover_data,ig.aud]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
